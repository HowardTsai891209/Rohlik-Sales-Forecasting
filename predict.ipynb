{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/sales_train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('data/sales_test.csv', parse_dates=['date'])\n",
    "ss = pd.read_csv('data/solution.csv')\n",
    "inventory = pd.read_csv('data/inventory.csv')\n",
    "weights = pd.read_csv('data/test_weights.csv')\n",
    "calendar = pd.read_csv('data/calendar.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# 定義節假日\n",
    "czech_holiday = [ \n",
    "    (['03/31/2024', '04/09/2023', '04/17/2022', '04/04/2021', '04/12/2020'], 'Easter Day'),#loss\n",
    "    (['05/12/2024', '05/10/2020', '05/09/2021', '05/08/2022', '05/14/2023'], \"Mother Day\"), #loss\n",
    "]\n",
    "brno_holiday = [\n",
    "    (['03/31/2024', '04/09/2023', '04/17/2022', '04/04/2021', '04/12/2020'], 'Easter Day'),#loss\n",
    "    (['05/12/2024', '05/10/2020', '05/09/2021', '05/08/2022', '05/14/2023'], \"Mother Day\"), #loss\n",
    "]\n",
    "\n",
    "budapest_holidays = []\n",
    "munich_holidays = [\n",
    "    (['03/30/2024', '04/08/2023', '04/16/2022', '04/03/2021'], 'Holy Saturday'),#loss\n",
    "    (['05/12/2024', '05/14/2023', '05/08/2022', '05/09/2021'], 'Mother Day'),#loss\n",
    "]\n",
    "\n",
    "frank_holidays = [\n",
    "    (['03/30/2024', '04/08/2023', '04/16/2022', '04/03/2021'], 'Holy Saturday'),#loss\n",
    "    (['05/12/2024', '05/14/2023', '05/08/2022', '05/09/2021'], 'Mother Day'),#loss\n",
    "]\n",
    "#填充節假日訊息\n",
    "def fill_loss_holidays(df_fill, warehouses, holidays):\n",
    "    df = df_fill.copy()\n",
    "    for item in holidays:\n",
    "        dates, holiday_name = item\n",
    "        generated_dates = [datetime.strptime(date, '%m/%d/%Y').strftime('%Y-%m-%d') for date in dates]\n",
    "        for generated_date in generated_dates:\n",
    "            df.loc[(df['warehouse'].isin(warehouses)) & (df['date'] == generated_date), 'holiday'] = 1\n",
    "            df.loc[(df['warehouse'].isin(warehouses)) & (df['date'] == generated_date), 'holiday_name'] = holiday_name\n",
    "    return df\n",
    "\n",
    "calendar = fill_loss_holidays(df_fill=calendar, warehouses=['Prague_1', 'Prague_2', 'Prague_3'], holidays=czech_holiday)\n",
    "calendar = fill_loss_holidays(df_fill=calendar, warehouses=['Brno_1'], holidays=brno_holiday)\n",
    "calendar = fill_loss_holidays(df_fill=calendar, warehouses=['Munich_1'], holidays=munich_holidays)\n",
    "calendar = fill_loss_holidays(df_fill=calendar, warehouses=['Frankfurt_1'], holidays=frank_holidays)\n",
    "calendar = fill_loss_holidays(df_fill=calendar, warehouses=['Budapest_1'], holidays=budapest_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查詢特定倉庫的節假日信息\n",
    "Frankfurt_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Frankfurt_1\"')\n",
    "Prague_2 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_2\"')\n",
    "Brno_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Brno_1\"')\n",
    "Munich_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Munich_1\"')\n",
    "Prague_3 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_3\"')\n",
    "Prague_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_1\"')\n",
    "Budapest_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Budapest_1\"')\n",
    "\n",
    "# 處理節假日信息\n",
    "def process_calendar(df):\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df['next_holiday_date'] = df.loc[df['holiday'] == 1, 'date'].shift(-1)\n",
    "    df['next_holiday_date'] = df['next_holiday_date'].bfill()\n",
    "    df['days_to_holiday'] = (df['next_holiday_date'] - df['date']).dt.days\n",
    "    df.drop(columns=['next_holiday_date'], inplace=True)\n",
    "    df['next_shops_closed_date'] = df.loc[df['shops_closed'] == 1, 'date'].shift(-1)\n",
    "    df['next_shops_closed_date'] = df['next_shops_closed_date'].bfill()\n",
    "    df['days_to_shops_closed'] = (df['next_shops_closed_date'] - df['date']).dt.days\n",
    "    df.drop(columns=['next_shops_closed_date'], inplace=True)\n",
    "    df['day_after_closing'] = (\n",
    "        (df['shops_closed'] == 0) & (df['shops_closed'].shift(1) == 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['long_weekend'] = (\n",
    "        (df['shops_closed'] == 1) & (df['shops_closed'].shift(1) == 1)\n",
    "    ).astype(int)\n",
    "    \n",
    "    df['weekday'] = df['date'].dt.weekday \n",
    "    return df\n",
    "dfs = ['Frankfurt_1', 'Prague_2', 'Brno_1', 'Munich_1', 'Prague_3', 'Prague_1', 'Budapest_1']\n",
    "processed_dfs = [process_calendar(globals()[df]) for df in dfs]\n",
    "calendar_extended = pd.concat(processed_dfs).sort_values('date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合併數據集\n",
    "train_calendar = train.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n",
    "train_inventory = train_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')\n",
    "train_data = train_inventory.merge(weights, on=['unique_id'], how='left')\n",
    "\n",
    "test_calendar = test.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n",
    "test_datas = test_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')\n",
    "\n",
    "train_data = train_data.drop(columns=['availability'])\n",
    "\n",
    "train_data.dropna(subset=['sales'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#處理特徵\n",
    "df=train_data\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['weekday'] = df['date'].dt.weekday\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['weekofyear'] = df['date'].dt.isocalendar().week\n",
    "df['dayofyear'] = df['date'].dt.dayofyear\n",
    "df['is_month_start'] = df['date'].dt.is_month_start\n",
    "df['is_month_end'] = df['date'].dt.is_month_end\n",
    "df['quarter'] = df['date'].dt.quarter\n",
    "df[\"total_dic\"]=df['type_0_discount']+df['type_0_discount']+df['type_1_discount']+df['type_2_discount']+df['type_3_discount']+df['type_4_discount']+df['type_5_discount']+df['type_6_discount']\n",
    "df['total_orders_']=df['total_orders']/df['sell_price_main']\n",
    "df['total_orders_dic']=df['total_orders_']/df[\"total_dic\"]\n",
    "df['total_orders_sell_price_main']=df['sell_price_main']/df[\"total_dic\"]\n",
    "for i in range(7):\n",
    "    df[f'total_orders{i}']=df[f'type_{i}_discount']/df[\"total_orders\"]\n",
    "    df[f'total_orders_sell_price_main_{i}']=df[f'type_{i}_discount']/df[\"total_orders_sell_price_main\"]\n",
    "    df[f'sell_price_main{i}']=df[f'type_{i}_discount']/df[\"sell_price_main\"]\n",
    "    df[f'sell_price_main_x_{i}']=df[f'type_{i}_discount']/(df[\"sell_price_main\"]*df[\"total_orders\"])\n",
    "    df[f'total_orders_dic{i}']=df[f'type_{i}_discount']/df[\"total_orders_dic\"]\n",
    "\n",
    "    df[f'_total_orders{i}']=df[f'type_{i}_discount']*df[\"total_orders\"]\n",
    "    df[f'_total_orders_sell_price_main_{i}']=df[f'type_{i}_discount']*df[\"total_orders_sell_price_main\"]\n",
    "    df[f'_sell_price_main{i}']=df[f'type_{i}_discount']*df[\"sell_price_main\"]\n",
    "    df[f'_total_orders_dic{i}']=df[f'type_{i}_discount']*df[\"total_orders_dic\"]\n",
    "\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "categorical_columns=['unique_id']+list(df.select_dtypes(\"object\").columns)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_test=test_datas\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "df_test['year'] = df_test['date'].dt.year\n",
    "df_test['month'] = df_test['date'].dt.month\n",
    "df_test['day'] = df_test['date'].dt.day\n",
    "df_test['weekday'] = df_test['date'].dt.weekday\n",
    "df_test['dayofweek'] = df_test['date'].dt.dayofweek\n",
    "df_test['weekofyear'] = df_test['date'].dt.isocalendar().week\n",
    "df_test['dayofyear'] = df_test['date'].dt.dayofyear\n",
    "df_test['is_month_start'] = df_test['date'].dt.is_month_start\n",
    "df_test['is_month_end'] = df_test['date'].dt.is_month_end\n",
    "df_test['quarter'] = df_test['date'].dt.quarter\n",
    "\n",
    "df_test[\"total_dic\"]=df_test['type_0_discount']+df_test['type_0_discount']+df_test['type_1_discount']+df_test['type_2_discount']+df_test['type_3_discount']+df_test['type_4_discount']+df_test['type_5_discount']+df_test['type_6_discount']\n",
    "df_test['total_orders_']=df_test['total_orders']/df_test['sell_price_main']\n",
    "df_test['total_orders_dic']=df_test['total_orders_']/df_test[\"total_dic\"]\n",
    "df_test['total_orders_sell_price_main']=df_test['sell_price_main']/df_test[\"total_dic\"]\n",
    "for i in range(7):\n",
    "    df_test[f'total_orders{i}']=df_test[f'type_{i}_discount']/df_test[\"total_orders\"]\n",
    "    df_test[f'total_orders_sell_price_main_{i}']=df_test[f'type_{i}_discount']/df_test[\"total_orders_sell_price_main\"]\n",
    "    df_test[f'sell_price_main{i}']=df_test[f'type_{i}_discount']/df_test[\"sell_price_main\"]\n",
    "    df_test[f'sell_price_main_x_{i}']=df_test[f'type_{i}_discount']/(df_test[\"sell_price_main\"]*df_test[\"total_orders_sell_price_main\"])\n",
    "    df_test[f'total_orders_dic{i}']=df_test[f'type_{i}_discount']/df_test[\"total_orders_dic\"]\n",
    "    df_test[f'_total_orders{i}']=df_test[f'type_{i}_discount']*df_test[\"total_orders\"]\n",
    "    df_test[f'_total_orders_sell_price_main_{i}']=df_test[f'type_{i}_discount']*df_test[\"total_orders_sell_price_main\"]\n",
    "    df_test[f'_sell_price_main{i}']=df_test[f'type_{i}_discount']*df_test[\"sell_price_main\"]\n",
    "    df_test[f'_total_orders_dic{i}']=df_test[f'type_{i}_discount']*df_test[\"total_orders_dic\"]\n",
    "df_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    df_test[col] = df_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練和測試數據的日期範圍\n",
    "train_start_date = '2020-08-01'\n",
    "train_end_date = '2024-03-18'\n",
    "test_start_date = '2024-03-18'\n",
    "test_end_date = '2024-06-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備訓練和測試數據\n",
    "X = df.drop(['sales', 'date','weight'], axis=1)\n",
    "y = df['sales']**(1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[(df['date'] < train_end_date)]\n",
    "test_data = df[(df['date'] >= test_start_date)]\n",
    "\n",
    "X_train = train_data.drop(['sales', 'date', 'weight'], axis=1)\n",
    "y_train = train_data['sales']**(1/8)\n",
    "train_weights = train_data['weight']\n",
    "\n",
    "X_test = test_data.drop(['sales', 'date', 'weight'], axis=1)\n",
    "y_test = test_data['sales']**(1/8)\n",
    "\n",
    "test_weights = test_data['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵縮放\n",
    "cols=X.select_dtypes([\"int\",\"float\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "sc = RobustScaler()\n",
    "\n",
    "for col in cols:\n",
    "    X_train[col].replace([np.inf, -np.inf], X_train[col].min(), inplace=True)\n",
    "    X_test[col].replace([np.inf, -np.inf], X_test[col].min(), inplace=True)\n",
    "\n",
    "    X_train[col].fillna(X_train[col].mean(), inplace=True)\n",
    "    X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "X_train[col] = sc.fit_transform(X_train[[col]])  \n",
    "X_test[col] = sc.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_indices = [X.columns.get_loc(col) for col in categorical_columns if col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's l1: 0.0885557\n",
      "[400]\tvalid_0's l1: 0.0820072\n",
      "[600]\tvalid_0's l1: 0.0792068\n",
      "[800]\tvalid_0's l1: 0.0779112\n",
      "[1000]\tvalid_0's l1: 0.0768244\n",
      "[1200]\tvalid_0's l1: 0.0756814\n",
      "[1400]\tvalid_0's l1: 0.074938\n",
      "[1600]\tvalid_0's l1: 0.0744681\n",
      "[1800]\tvalid_0's l1: 0.0741401\n",
      "[2000]\tvalid_0's l1: 0.0738613\n",
      "[2200]\tvalid_0's l1: 0.0735561\n",
      "[2400]\tvalid_0's l1: 0.0733461\n",
      "[2600]\tvalid_0's l1: 0.0731742\n",
      "[2800]\tvalid_0's l1: 0.0729826\n",
      "[3000]\tvalid_0's l1: 0.072814\n",
      "[3200]\tvalid_0's l1: 0.0727186\n",
      "[3400]\tvalid_0's l1: 0.0723859\n",
      "[3600]\tvalid_0's l1: 0.0722705\n",
      "[3800]\tvalid_0's l1: 0.0721744\n",
      "[4000]\tvalid_0's l1: 0.0720761\n",
      "[4200]\tvalid_0's l1: 0.071982\n",
      "[4400]\tvalid_0's l1: 0.071913\n",
      "[4600]\tvalid_0's l1: 0.0718493\n",
      "[4800]\tvalid_0's l1: 0.0717889\n",
      "[5000]\tvalid_0's l1: 0.0716971\n",
      "[5200]\tvalid_0's l1: 0.0716348\n",
      "[5400]\tvalid_0's l1: 0.0716016\n",
      "[5600]\tvalid_0's l1: 0.0715517\n",
      "[5800]\tvalid_0's l1: 0.0715348\n",
      "[6000]\tvalid_0's l1: 0.0715413\n",
      "[6200]\tvalid_0's l1: 0.0715275\n",
      "[6400]\tvalid_0's l1: 0.0715134\n",
      "[6600]\tvalid_0's l1: 0.0715154\n",
      "[6800]\tvalid_0's l1: 0.071537\n",
      "[7000]\tvalid_0's l1: 0.0715302\n",
      "[7200]\tvalid_0's l1: 0.0715261\n",
      "[7400]\tvalid_0's l1: 0.0714885\n",
      "[7600]\tvalid_0's l1: 0.0715121\n",
      "[7800]\tvalid_0's l1: 0.071561\n",
      "[8000]\tvalid_0's l1: 0.0715937\n",
      "[8200]\tvalid_0's l1: 0.0715995\n",
      "[8400]\tvalid_0's l1: 0.0716294\n",
      "[8600]\tvalid_0's l1: 0.0716442\n",
      "[8800]\tvalid_0's l1: 0.0716531\n",
      "[9000]\tvalid_0's l1: 0.0716447\n",
      "[9200]\tvalid_0's l1: 0.0716416\n",
      "[9400]\tvalid_0's l1: 0.0716542\n",
      "[9600]\tvalid_0's l1: 0.0716532\n",
      "[9800]\tvalid_0's l1: 0.0716669\n",
      "[10000]\tvalid_0's l1: 0.0716696\n",
      "[10200]\tvalid_0's l1: 0.0716815\n",
      "[10400]\tvalid_0's l1: 0.0716988\n",
      "[10600]\tvalid_0's l1: 0.0717038\n",
      "[10800]\tvalid_0's l1: 0.0717179\n",
      "[11000]\tvalid_0's l1: 0.0717037\n",
      "\n",
      "Final Model Performance:\n",
      "Weight Mean Absolute Error: 21.927032051106018\n"
     ]
    }
   ],
   "source": [
    "# 訓練LightGBM模型\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "callbacks = [log_evaluation(period=200)]\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.021796506746095975,  # 學習率\n",
    "    'num_leaves': 93,  # 樹葉節點數\n",
    "    'max_depth': 10,  # 樹的最大深度\n",
    "    'min_child_samples': 25,  # 子葉節點的最小樣本數\n",
    "    'subsample': 0.7057135664023435,  # 每棵樹的樣本比例\n",
    "    'colsample_bytree': 0.8528497905459008,  # 每棵樹的特徵比例\n",
    "    'reg_alpha': 0.036786449788597686,  # L1正則化\n",
    "    'reg_lambda': 0.3151110021900479,  # L2正則化\n",
    "    'num_boost_round': 11000,  # 提升迭代次數\n",
    "    'objective': 'regression',  # 目標函數，這裡是回歸\n",
    "    'metric': 'mae',  # 評估指標，這裡是平均絕對誤差\n",
    "    'boosting_type': 'gbdt',  # 提升類型，這裡是梯度提升決策樹\n",
    "    'verbose': -1  # 設定為-1表示不輸出訓練過程中的信息\n",
    "}\n",
    "\n",
    "final_train_dataset = lgb.Dataset(\n",
    "    X,  # 特徵數據\n",
    "    label=y,  # 標籤數據\n",
    "    categorical_feature=categorical_feature_indices,  # 類別特徵的索引\n",
    "    weight=df['weight']  # 樣本權重\n",
    ")\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,  # 模型參數\n",
    "    final_train_dataset,  # 訓練數據集\n",
    "    num_boost_round=params['num_boost_round'],  # 提升迭代次數\n",
    "    callbacks=callbacks  # 回調函數\n",
    ")\n",
    "\n",
    "final_y_pred = final_model.predict(X_test, num_iteration=final_model.best_iteration)\n",
    "weighted_mae = np.sum(test_weights * np.abs(y_test**(8) - final_y_pred**(8))) / np.sum(test_weights)\n",
    "\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f'Weight Mean Absolute Error: {weighted_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵縮放\n",
    "sc = RobustScaler()\n",
    "\n",
    "for col in cols:\n",
    "    X[col].replace([np.inf, -np.inf], X[col].min(), inplace=True)  # 替換無窮大和無窮小值\n",
    "    df_test[col].replace([np.inf, -np.inf], df_test[col].min(), inplace=True)\n",
    "\n",
    "    X[col].fillna(X[col].mean(), inplace=True)  # 填充缺失值\n",
    "    df_test[col].fillna(df_test[col].mean(), inplace=True)\n",
    "\n",
    "X[cols] = sc.fit_transform(X[cols])  # 對訓練數據進行縮放\n",
    "df_test[cols] = sc.transform(df_test[cols])  # 對測試數據進行縮放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置LightGBM的回調函數和參數\n",
    "callbacks = [log_evaluation(period=200)]\n",
    "\n",
    "params={'learning_rate': 0.021796506746095975,  # 學習率\n",
    " 'num_leaves': 93,  # 樹葉節點數\n",
    " 'max_depth': 10,  # 樹的最大深度\n",
    " 'min_child_samples': 25,  # 子葉節點的最小樣本數\n",
    " 'subsample': 0.7057135664023435,  # 每棵樹的樣本比例\n",
    " 'colsample_bytree': 0.8528497905459008,  # 每棵樹的特徵比例\n",
    " 'reg_alpha': 0.036786449788597686,  # L1正則化\n",
    " 'reg_lambda': 0.3151110021900479,  # L2正則化\n",
    " 'num_boost_round': 11000,  # 提升迭代次數\n",
    " 'objective': 'regression',  # 目標函數，這裡是回歸\n",
    " 'metric': 'mae',  # 評估指標，這裡是平均絕對誤差\n",
    " 'boosting_type': 'gbdt',  # 提升類型，這裡是梯度提升決策樹\n",
    " 'verbose': -1}  # 設定為-1表示不輸出訓練過程中的信息\n",
    "\n",
    "# 準備LightGBM的訓練數據集\n",
    "final_train_dataset = lgb.Dataset(X, label=y, \n",
    "                                  categorical_feature=categorical_feature_indices,\n",
    "                                  weight=df['weight'])\n",
    "# 訓練LightGBM模型\n",
    "final_model = lgb.train(params, \n",
    "                        final_train_dataset, \n",
    "                        num_boost_round=params['num_boost_round'],\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用訓練好的模型進行預測\n",
    "final_y_pred = final_model.predict(df_test.drop(['date'], axis=1), num_iteration=final_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備提交結果\n",
    "sub=df_test.copy()\n",
    "sub['sales_hat']=final_y_pred**(8)  # 將預測值還原\n",
    "sub['id']=sub['unique_id'].astype(str) + \"_\" + sub['date'].astype(str)\n",
    "sub[['id','sales_hat']].to_csv(\"submission.csv\",index=False)  # 將結果保存為CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    資料集       筆數\n",
      "0  訓練資料  4007419\n",
      "1  測試資料    47021\n",
      "2    總和  4054440\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假設你已經有訓練集和測試集的 DataFrame\n",
    "train_data = pd.read_csv('data/sales_train.csv')\n",
    "test_data = pd.read_csv('data/sales_test.csv')\n",
    "\n",
    "# 計算每個資料集的筆數\n",
    "train_count = len(train_data)\n",
    "test_count = len(test_data)\n",
    "total_count = train_count + test_count\n",
    "\n",
    "# 建立 DataFrame 來顯示結果\n",
    "summary_df = pd.DataFrame({\n",
    "    '資料集': ['訓練資料', '測試資料', '總和'],\n",
    "    '筆數': [train_count, test_count, total_count]\n",
    "})\n",
    "\n",
    "# 顯示結果\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          項目            數值\n",
      "0       模型出處      LightGBM\n",
      "1  模型大小 (KB)  87755.418945\n",
      "2   訓練時間 (秒)    341.673715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 讀取訓練資料和測試資料\n",
    "train_data = pd.read_csv('data/sales_train.csv')\n",
    "test_data = pd.read_csv('data/sales_test.csv')\n",
    "\n",
    "# 將日期轉換為數值型特徵\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "train_data['year'] = train_data['date'].dt.year\n",
    "train_data['month'] = train_data['date'].dt.month\n",
    "train_data['day'] = train_data['date'].dt.day\n",
    "train_data['day_of_week'] = train_data['date'].dt.dayofweek\n",
    "\n",
    "# 將類別型特徵轉換為數值型特徵\n",
    "train_data['warehouse'] = train_data['warehouse'].astype('category').cat.codes\n",
    "\n",
    "# 訓練數據和標籤\n",
    "X_train = train_data.drop(columns=['sales', 'date'])\n",
    "y_train = train_data['sales']\n",
    "\n",
    "# 設置LightGBM的回調函數和參數\n",
    "callbacks = [lgb.log_evaluation(period=200)]\n",
    "params = {\n",
    "    'learning_rate': 0.021796506746095975,\n",
    "    'num_leaves': 93,\n",
    "    'max_depth': 10,\n",
    "    'min_child_samples': 25,\n",
    "    'subsample': 0.7057135664023435,\n",
    "    'colsample_bytree': 0.8528497905459008,\n",
    "    'reg_alpha': 0.036786449788597686,\n",
    "    'reg_lambda': 0.3151110021900479,\n",
    "    'num_boost_round': 11000,\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# 準備LightGBM的訓練數據集\n",
    "train_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# 訓練LightGBM模型並計算訓練時間\n",
    "start_time = time.time()\n",
    "model = lgb.train(params, train_dataset, callbacks=callbacks)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# 保存模型到文件並計算模型大小\n",
    "model_file = 'lightgbm_model.txt'\n",
    "model.save_model(model_file)\n",
    "model_size = os.path.getsize(model_file) / 1024  # 以KB為單位\n",
    "\n",
    "# 模型出處\n",
    "model_source = 'LightGBM'\n",
    "\n",
    "# 建立 DataFrame 來顯示結果\n",
    "summary_df = pd.DataFrame({\n",
    "    '項目': ['模型出處', '模型大小 (KB)', '訓練時間 (秒)'],\n",
    "    '數值': [model_source, model_size, training_time]\n",
    "})\n",
    "\n",
    "# 顯示結果\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rohlik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
